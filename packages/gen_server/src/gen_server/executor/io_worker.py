import asyncio
import logging
import multiprocessing
from queue import Empty
from PIL import Image, PngImagePlugin
import torch

from ..utils.file_handler import FileHandler
from ..utils.image import tensor_to_pil

logger = logging.getLogger(__name__)


def run_io_worker(
    tensor_queue: multiprocessing.Queue,
    file_handler: FileHandler
):
    asyncio.run(start_io_worker(tensor_queue, file_handler))


async def start_io_worker(
    tensor_queue: multiprocessing.Queue,
    file_handler: FileHandler
):
    processing_tasks = set()
    
    while True:
        try:
            # Try to get a new batch from the queue
            try:
                tensor_batch, response_conn = tensor_queue.get_nowait()
                if tensor_batch is None:
                    # GPU worker is done with this connection
                    response_conn.send(None)
                    continue
                
                # Start processing the new batch
                task = asyncio.create_task(
                    upload_batch(file_handler, tensor_batch, response_conn)
                )
                processing_tasks.add(task)
                task.add_done_callback(processing_tasks.discard)
            
            except Empty:
                # No new job, continue with ongoing tasks
                pass
            
            # Yield control of the thread to allow for I/O operations and to check for new batches
            await asyncio.sleep(0)
            
            # Clean up completed tasks
            done_tasks = [t for t in processing_tasks if t.done()]
            for task in done_tasks:
                processing_tasks.remove(task)
                try:
                    await task
                except Exception as e:
                    logger.error(f"Error in batch processing: {str(e)}")
        
        except Exception as e:
            logger.error(f"Unexpected error in io-worker: {str(e)}")
    
    # Wait for all remaining tasks to complete before shutting down
    await asyncio.gather(*processing_tasks)
    logger.info("IO-worker shut down complete")


async def upload_batch(
    file_handler: FileHandler,
    tensor_batch: list[torch.Tensor],
    response_conn: multiprocessing.connection.Connection
):
    metadata = PngImagePlugin.PngInfo()
    metadata.add_text("Description", "Generated by gen_server")
    metadata.add_text("Author", "gen_server")
    
    pil_images = [tensor_to_pil(tensor) for tensor in tensor_batch]
    
    async for file_url in file_handler.upload_png_files(pil_images, metadata):
        response_conn.send(file_url)
