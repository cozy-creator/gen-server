# In io_worker.py
import multiprocessing
from multiprocessing.connection import Connection
import multiprocessing.queues
import torch
from PIL import Image, PngImagePlugin
import logging

from ..utils.file_handler import FileHandler

logger = logging.getLogger(__name__)


# TO DO: is this permutation correct?
# TO DO: handle tensors with an alpha-channel maybe?
def tensor_to_pil(tensor: torch.Tensor) -> Image.Image:
    return Image.fromarray(tensor.byte().permute(1, 2, 0).cpu().numpy())


async def run_io_worker(
    tensor_queue: multiprocessing.Queue, 
    response_conn: Connection,
    file_handler: FileHandler
):
    try:
        while True:
            try:
                tensor_batch = tensor_queue.get(timeout=120)
                if tensor_batch is None:  # Signal to stop
                    break
                
                metadata = PngImagePlugin.PngInfo()
                metadata.add_text("Description", "Generated by gen_server")
                metadata.add_text("Author", "gen_server")
                
                pil_images = []
                for tensor in tensor_batch:
                    pil_image = tensor_to_pil(tensor)
                    pil_images.append(pil_image)
                
                async for file_url in file_handler.upload_png_files(pil_images, metadata):
                    response_conn.send(file_url)

            except queue.Empty:
                logger.warning("Timeout waiting for tensor batch")

    except Exception as e:
        logger.error(f"Error in process_and_upload_images: {str(e)}")
        response_conn.send(None)  # Signal error to API server
    finally:
        response_conn.send(StopIteration)  # Signal end of stream
        response_conn.close()
        tensor_queue.close()  # Close the queue from the IO process side